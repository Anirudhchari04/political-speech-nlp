{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing Audio Files with Wav2Vec2\n",
    "\n",
    "Transcribing audio into text can be really tedious and time-consuming. So, I was excited to try out [Hugging Face's Wav2Vec2 model](https://huggingface.co/transformers/model_doc/wav2vec2.html)\n",
    "\n",
    "### My Experiments\n",
    "\n",
    "I tested the model on different types of speeches and accents, including:\n",
    "\n",
    "- **Short audio snippets (62s)**\n",
    "- **A poetry recital (5m 34s)**\n",
    "- **A longer political speech (12+ minutes)**\n",
    "\n",
    "The results were impressive, making it easier to use NLP tasks directly from audio to text.\n",
    "\n",
    "### Challenges\n",
    "\n",
    "Longer audio clips (over 90 seconds) were a bit tricky and tended to crash normal work machines.\n",
    "\n",
    "### References and Resources\n",
    "\n",
    "- Check out the [Wav2Vec2 documentation](https://huggingface.co/transformers/model_doc/wav2vec2.html).\n",
    "- Use the [inference API on Hugging Face](https://huggingface.co/facebook/wav2vec2-base-960h).\n",
    "- Read the paper on [wav2vec 2.0](https://arxiv.org/abs/2006.11477).\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- **transformers** >= 4.3\n",
    "- **librosa**\n",
    "\n",
    "If you want to use your own audio clips, make sure to downsample them to 16kHz, as Wav2Vec2 was trained on 16kHz audio. I used [Audacity](https://www.audacityteam.org/) for this.\n",
    "\n",
    "### Models\n",
    "\n",
    "There are various Wav2Vec2 models on Hugging Face's model hub. This project used the [wav2vec2-base-960h](https://huggingface.co/facebook/wav2vec2-base-960h) model. You can explore other models [here](https://huggingface.co/models?search=wav2ve)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TRANSCRIBE SHORT AUDIO CLIP\n",
    "\n",
    "The included file is a 62-second clip from John F. Kennedy's famous inaugural speech in 1961. You can swap it with any other English speech you want.\n",
    "\n",
    "It seems to work only for English speeches.\n",
    "\n",
    "If the audio clip is longer than 90 seconds, the notebook might crash, due to memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "b1dL-TWaiL2_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_7_kYLbkiTBF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\aniru\\.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "C:\\Users\\aniru\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\wav2vec2\\tokenization_wav2vec2.py:720: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#load tokenizer and pre-trained model\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZHVYnywjEu0",
    "outputId": "61ace4a1-b603-4bb3-b79e-4a96d089df22"
   },
   "outputs": [],
   "source": [
    "#load audio file from folder of choice\n",
    "file_path = \"../audio/jfk.flac\"\n",
    "\n",
    "speech, rate = librosa.load(file_path,sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EKKsO6TsjToR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.5 s\n",
      "Wall time: 4.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_values = tokenizer(speech, return_tensors = 'pt').input_values\n",
    "\n",
    "#Store logits (non-normalized predictions)\n",
    "logits = model(input_values).logits\n",
    "\n",
    "#Store predicted id's\n",
    "predicted_ids = torch.argmax(logits, dim =-1)\n",
    "\n",
    "#decode the audio to generate text\n",
    "transcript = tokenizer.decode(predicted_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "scP9E_yPrGpq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN THE LONG HISTORY OF THE WORLD ONLY A FEW GENERATIONS HAVE BEEN GRANDED THE ROLE OF DEFENDING FREEDOM IN ITS OUR MAXIMUM DANGER I DO NOT SHRINK FROM THIS RESPONSIBILITY I WELCOME IT    I DO NOT BELIEVE THAT ANY OF US WOULD EXCHANGE PLACES WITH ANY OTHER PEOPLE OR ANY OTHER GENERATION THE ENERGY THE FAITH THE DEVOTION WHICH WANGE BRANG TO THIS AND OF UP WILL NOT OUR COUNTRY AND ALL WHO SERVE IT AND THE GLOW FROM THAT FIRE CAND TRULY LIKE THE WORLD AND SO MY FELLOW AMERICA ASK NOT WHAT YOUR COUNTRY CAN DO FOR YOU ASK WHAT YOU CAN DO FOR YOUR COUNTRY\n"
     ]
    }
   ],
   "source": [
    "print(transcript)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "wav2vec2_transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
